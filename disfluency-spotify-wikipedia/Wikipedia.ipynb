{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd72125-5c06-4589-ae8d-eb6ca0fb9eef",
   "metadata": {},
   "source": [
    "# Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e4e0e7-64ba-48a9-9cd9-2715dccb5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import os\n",
    "import difflib\n",
    "\n",
    "import utils_general\n",
    "import utils_transformations\n",
    "\n",
    "f = \"/data2/maria/wiki-split/test.tsv\"\n",
    "\n",
    "df = pd.read_csv(f, sep=\"\\t\", header=None)\n",
    "\n",
    "def write_wikipedia_files_out():\n",
    "    \n",
    "    WIKIPEDIA_DIR = os.path.join(\".\", \"wikipedia\")\n",
    "    utils_general.create_and_or_clear_this_dir(WIKIPEDIA_DIR)\n",
    "\n",
    "    rng = np.random.default_rng(seed=0)\n",
    "\n",
    "    # n = 0\n",
    "    zero_dir = os.path.join(WIKIPEDIA_DIR, \"0\")\n",
    "    utils_general.just_create_this_dir(zero_dir)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        sentence = df.iloc[i,0]\n",
    "\n",
    "        # shift punctuation\n",
    "        sentence = re.sub(r\"\\s*,\\s*\", \", \", sentence)\n",
    "        sentence = re.sub(r\"\\s*\\.\\s*\", \". \", sentence)\n",
    "        sentence = re.sub(r\"\\s*\\;\\s*\", \"; \", sentence)\n",
    "        sentence = re.sub(r\"\\s*\\:\\s*\", \": \", sentence)\n",
    "        sentence = re.sub(r\"\\s*\\!\\s*\", \"! \", sentence)\n",
    "        sentence = re.sub(r\"\\s*\\?\\s*\", \"? \", sentence)\n",
    "\n",
    "        # special case\n",
    "        sentence = sentence.replace(\" n't\",\"n't\")\n",
    "        sentence = re.sub(r\"''\",\"'\", sentence)\n",
    "        sentence = re.sub(r\"'\\s*'\",\"'\", sentence)\n",
    "        sentence = re.sub(r\"' ([^']+?) '\", r\" '\\1'\", sentence)\n",
    "        sentence = re.sub(r\"\\( ([^']+?) \\)\", r\"(\\1)\", sentence)\n",
    "        sentence = re.sub(r\"\\b\\s'\", \"'\", sentence)\n",
    "        sentence = re.sub(r\"\\.\\s*\\.\\s*\\.\", \"...\", sentence)\n",
    "        sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "        sentence = sentence.strip()\n",
    "\n",
    "        sentence = utils_transformations.get_repeats_text(0, sentence, rng)\n",
    "        utils_general.write_file(str(i) + \".txt\", zero_dir, sentence) \n",
    "\n",
    "        for t in [\"repeats\",\"interjections\",\"false-starts\",\"repeats-and-false-starts\",\"repeats-and-interjections\",\"interjections-and-false-starts\",\"all-3\"]:\n",
    "            current_trf_dir = os.path.join(WIKIPEDIA_DIR, t)\n",
    "            utils_general.just_create_this_dir(current_trf_dir)\n",
    "\n",
    "            # n = 1, 2, ..., 10\n",
    "            for n in [1,2,3,4,5,6,7,8,9,10]:\n",
    "\n",
    "                # reset the sentence\n",
    "                sentence = utils_general.read_file(os.path.join(zero_dir, str(i) + \".txt\"))\n",
    "\n",
    "                # transform the sentence and write it out to file\n",
    "                new_filename = str(n) + \"_\" + str(i) + \".txt\"\n",
    "\n",
    "                if t == \"repeats\":\n",
    "                    sentence = utils_transformations.get_repeats_text(n, sentence, rng)\n",
    "\n",
    "                elif t == \"interjections\":\n",
    "                    sentence = utils_transformations.get_interjections_text(n, sentence, rng)  \n",
    "\n",
    "                elif t == \"false-starts\":\n",
    "                    sentence = utils_transformations.get_false_starts_text(n, sentence, rng)\n",
    "\n",
    "                elif t == \"repeats-and-false-starts\":\n",
    "                    sentence = utils_transformations.get_repeats_text(n, sentence, rng)\n",
    "                    sentence = utils_transformations.get_false_starts_text(n, sentence, rng)\n",
    "\n",
    "                elif t == \"repeats-and-interjections\":\n",
    "                    sentence = utils_transformations.get_repeats_text(n, sentence, rng)\n",
    "                    sentence = utils_transformations.get_interjections_text(n, sentence, rng) \n",
    "\n",
    "                elif t == \"interjections-and-false-starts\":\n",
    "                    sentence = utils_transformations.get_interjections_text(n, sentence, rng)\n",
    "                    sentence = utils_transformations.get_false_starts_text(n, sentence, rng)\n",
    "\n",
    "                elif t == \"all-3\":\n",
    "                    sentence = utils_transformations.get_interjections_text(n, sentence, rng)\n",
    "                    sentence = utils_transformations.get_false_starts_text(n, sentence, rng)\n",
    "                    sentence = utils_transformations.get_repeats_text(n, sentence, rng)  \n",
    "\n",
    "                utils_general.write_file(new_filename, current_trf_dir, sentence)\n",
    "                \n",
    "write_wikipedia_files_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b03c16-4c81-4f77-8d7c-9749c6843654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Bandolier - Budgie', a free iTunes app for iPad, iPhone and iPod touch, released in December 2011, tells the story of the making of Bandolier in the band's own words - including an extensive audio interview with Burke Shelley. \n",
      "\n",
      "'Bandolier - Budgie', a free iTunes app for iPad, iPad, iPad, iPad, iPhone and iPod touch, released in December 2011, 2011, 2011, 2011, tells the story of the making of Bandolier in in in in the band's own words - including an extensive audio interview with Burke Shelley. \n",
      "\n",
      "'Bandolier - Budgie', a free iTunes app for iPad, iPhone uh well okay and iPod touch, released in December 2011, tells the uh so okay story of the making of Bandolier in the band's own words - including an extensive audio interview with Burke Shelley. \n",
      "\n",
      "'Bandolier - Budgie', a free iTunes app for iPad, iPhone and iPod touch, released in December 2011, tells the story of the making of Bandolier in the band's own words - including an extensive audio interview with Burke Shelley. \n",
      "\n",
      "'Bandolier - Budgie', a free iTunes app well okay okay okay okay like for iPad, iPhone and iPod touch, released in in in in December 2011, tells you know like well the story story story story of the making of Bandolier in the I mean mean mean mean I mean you know band's own words - including an extensive audio interview with Burke Shelley. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,1):\n",
    "    id_str = str(i)\n",
    "    print(utils_general.read_file(os.path.join(\".\", \"wikipedia\", \"0\", f\"{id_str}.txt\")), \"\\n\")\n",
    "    print(utils_general.read_file(os.path.join(\".\", \"wikipedia\", \"repeats\", f\"3_{id_str}.txt\")), \"\\n\")\n",
    "    print(utils_general.read_file(os.path.join(\".\", \"wikipedia\", \"interjections\", f\"3_{id_str}.txt\")), \"\\n\")\n",
    "    print(utils_general.read_file(os.path.join(\".\", \"wikipedia\", \"false-starts\", f\"3_{id_str}.txt\")), \"\\n\")\n",
    "    print(utils_general.read_file(os.path.join(\".\", \"wikipedia\", \"all-3\", f\"3_{id_str}.txt\")), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f13b75-230e-440a-9da2-8b452535a3c4",
   "metadata": {},
   "source": [
    "## Reproducibility Checks\n",
    "\n",
    "Makes sure that the output of these 3 files (selected randomly) is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6677da56-7f57-482d-a26e-96e2076e668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "random_file_1_path = os.path.join(\".\", \"wikipedia\", \"repeats-and-false-starts\",\"8_1.txt\")\n",
    "random_file_2_path = os.path.join(\".\", \"wikipedia\", \"interjections\",\"6_3908.txt\")\n",
    "random_file_3_path = os.path.join(\".\", \"wikipedia\", \"all-3\",\"4_432.txt\")\n",
    "\n",
    "# reads the output of 3 files\n",
    "random_file_1 = utils_general.read_file(random_file_1_path)\n",
    "random_file_2 = utils_general.read_file(random_file_2_path)\n",
    "random_file_3 = utils_general.read_file(random_file_3_path)\n",
    "\n",
    "# re-runs the writing files out & transformations\n",
    "write_wikipedia_files_out()\n",
    "run2_random_file_1 = utils_general.read_file(random_file_1_path)\n",
    "run2_random_file_2 = utils_general.read_file(random_file_2_path)\n",
    "run2_random_file_3 = utils_general.read_file(random_file_3_path)\n",
    "\n",
    "# ensures that the new files are the same as the old files\n",
    "print(list(difflib.unified_diff(random_file_1.split(\" \"), run2_random_file_1.split(\" \"))))\n",
    "print(list(difflib.unified_diff(random_file_2.split(\" \"), run2_random_file_2.split(\" \"))))\n",
    "print(list(difflib.unified_diff(random_file_3.split(\" \"), run2_random_file_3.split(\" \"))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
